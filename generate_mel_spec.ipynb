{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import joblib\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa as lb\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mm\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_THREADS = mm.cpu_count() - 1\n",
    "files = glob.glob('test/*.flac')\n",
    "new_dir = 'mel_32_128_2'\n",
    "\n",
    "OUT_TRAIN = f'{new_dir}/train'\n",
    "OUT_TEST = f'{new_dir}/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class params:\n",
    "    sr = 32000\n",
    "    n_mels = 128\n",
    "    fmin = 0\n",
    "    fmax = 14000\n",
    "    mel_power = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_melspec(y, params):\n",
    "    \"\"\"\n",
    "    Computes a mel-spectrogram and puts it at decibel scale\n",
    "    Arguments:\n",
    "        y {np array} - signal\n",
    "        params {AudioParams} - Parameters to use for the spectrogram. Expected to have the attributes sr, n_mels, f_min, f_max\n",
    "    Returns:\n",
    "        np array - Mel-spectrogram\n",
    "    \"\"\"\n",
    "    melspec = lb.feature.melspectrogram(\n",
    "        y, sr=params.sr, n_mels=params.n_mels, fmin=params.fmin, fmax=params.fmax\n",
    "    )\n",
    "\n",
    "    melspec = lb.power_to_db(melspec, params.mel_power).astype(np.float32)\n",
    "    return melspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_save(record, out_dir):\n",
    "    \"\"\"\n",
    "    Load the audio files and convert to melspectogram and then store as .npy files\n",
    "    Arguments:\n",
    "        record {String} - full directory of input file\n",
    "        out_dir {String} - directory to save .npy files\n",
    "    \"\"\"\n",
    "    y, _ = lb.load(record, params.sr)\n",
    "    melspec = compute_melspec(y, params)\n",
    "    \n",
    "    record_name = record.split('/')[-1]\n",
    "    output_name = record_name.replace('.flac', '.npy')\n",
    "    \n",
    "    np.save(f'{out_dir}/{output_name}', melspec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = glob.glob('train/*.flac')\n",
    "test_files = glob.glob('test/*.flac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = joblib.Parallel(n_jobs=NUM_THREADS)(\n",
    "    joblib.delayed(load_and_save)(i,j) for i,j in tqdm(zip(train_files, [OUT_TRAIN]*len(train_files)), total=len(train_files))\n",
    ")\n",
    "_ = joblib.Parallel(n_jobs=NUM_THREADS)(\n",
    "    joblib.delayed(load_and_save)(i,j) for i,j in tqdm(zip(test_files, [OUT_TEST]*len(test_files)), total=len(test_files))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X, eps=1e-6, mean=None, std=None):\n",
    "    \"\"\"\n",
    "    Normalizes the image and converts to a range of 0-255\n",
    "    Arguments:\n",
    "        X {numpy array [H x W]} - 2D array to convert\n",
    "        eps {float} -- To avoid dividing by 0 (default: {1e-6})\n",
    "        mean {None or np array} - Mean for normalization (default: {None})\n",
    "        std {None or np array} - Std for normalization (default: {None})\n",
    "    Returns:\n",
    "        numpy array [H x W] - numpy array\n",
    "    \"\"\"\n",
    "    mean = mean or X.mean()\n",
    "    std = std or X.std()\n",
    "    X = (X - mean) / (std + eps)\n",
    "\n",
    "    _min, _max = X.min(), X.max()\n",
    "\n",
    "    if (_max - _min) > eps:\n",
    "        V = np.clip(X, _min, _max)\n",
    "        V = 255 * (V - _min) / (_max - _min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        V = np.zeros_like(X, dtype=np.uint8)\n",
    "\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(f'{new_dir}.hdf5', mode='w') as f:    \n",
    "    train_files = glob.glob(f'{new_dir}/train/*')\n",
    "    test_files = glob.glob(f'{new_dir}/test/*')\n",
    "    \n",
    "    # Collect the mean and std over all records\n",
    "    mean = []\n",
    "    std = []\n",
    "    for i in tqdm(train_files + test_files):\n",
    "        file = np.load(i)\n",
    "        mean.append(file.mean())\n",
    "        std.append(file.std())\n",
    "    \n",
    "    mean = np.array(mean).mean()\n",
    "    std = np.array(std).mean()    \n",
    "    \n",
    "    base = np.load(train_files[0])\n",
    "    shape = (len(train_files), *base.shape)\n",
    "    \n",
    "    f.create_dataset('train_files', (len(train_files), *base.shape), np.uint8)\n",
    "    f.create_dataset('test_files', (len(test_files), *base.shape), np.uint8)\n",
    "    \n",
    "    dt = h5py.special_dtype(vlen=str)\n",
    "    \n",
    "    f.create_dataset('train_labels', (len(train_files),), 'S10')\n",
    "    f.create_dataset('test_labels', (len(test_files),), 'S10')\n",
    "    \n",
    "    # Save the names of all the recording_ids\n",
    "    f['train_labels'][...] = [i.split('/')[-1].split('.')[0].encode(\"ascii\", \"ignore\") for i in train_files]\n",
    "    f['test_labels'][...] = [i.split('/')[-1].split('.')[0].encode(\"ascii\", \"ignore\") for i in test_files]\n",
    "\n",
    "    for i, v in tqdm(enumerate(train_files), total=len(train_files)):\n",
    "        f['train_files'][i, ...] = normalize(np.load(v), mean=mean, std=std)\n",
    "        \n",
    "    for i, v in tqdm(enumerate(test_files), total=len(test_files)):\n",
    "        f['test_files'][i, ...] = normalize(np.load(v), mean=mean, std=std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all the .npy files\n",
    "shutil.rmtree(new_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

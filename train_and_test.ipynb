{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "thB6XvcCnsfM",
    "outputId": "954257de-1772-42bc-ab9e-58ebbb0665fe"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import files, drive\n",
    "drive.mount('/content/drive')\n",
    "os.chdir('/')\n",
    "DRIVE_PATH = 'content/drive/MyDrive/Colab Notebooks/kaggle_rainforest'\n",
    "f = []\n",
    "for (dirpath, dirnames, filenames) in os.walk('.'):\n",
    "    f.extend(dirnames)\n",
    "    break\n",
    "    \n",
    "# Only change the directory if the \"models\" folder is not accessible \n",
    "if 'models' not in f:\n",
    "    os.chdir(f'{DRIVE_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sRImtbU6J5U5",
    "outputId": "bf3c8164-c791-4a2f-9c7a-e036af53804f"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y2UZpG6FZhCJ"
   },
   "outputs": [],
   "source": [
    "!pip install transformers resnest efficientnet_pytorch &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4-KKBOzln4d7"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import math\n",
    "import datetime\n",
    "import time\n",
    "import h5py\n",
    "import multiprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold, train_test_split\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "import resnest.torch as resnest_torch\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqQyQQfFnO7L"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tOy3Onv0GPSA"
   },
   "outputs": [],
   "source": [
    "NUM_WORKERS = multiprocessing.cpu_count()\n",
    "MEL_FILE = 'mel_32_128_2'\n",
    "NUM_CLASSES = 24\n",
    "CUT = 6\n",
    "SAMPLE_TIME = 4\n",
    "HEIGHT, WIDTH = 300, 300\n",
    "AUDIO_LENGTH = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PpI_TZpS3aDo",
    "outputId": "6e63769f-aecb-49bc-f77f-921272d12366"
   },
   "outputs": [],
   "source": [
    "def extract_dataset(label, h5file):\n",
    "    \"\"\"\n",
    "    Extracts data from the h5 file and stores into a dictionary\n",
    "    Arguments:\n",
    "        label {String} - train or test set\n",
    "        h5File {String} - filename of the hdf5 file\n",
    "    Returns:\n",
    "        dictionary {recording_id: [h, w]}\n",
    "    \"\"\"\n",
    "    dataset = h5py.File(f'mel/{h5file}.hdf5', 'r')\n",
    "    recording_ids = [i.decode('utf-8') for i in dataset[f'{label}_labels']]\n",
    "    data = {k:v for k, v in tqdm(zip(recording_ids, dataset[f'{label}_files']), total=len(recording_ids))}\n",
    "    return data\n",
    "\n",
    "# Load data into memory for faster training\n",
    "train_data = extract_dataset('train', MEL_FILE)\n",
    "test_data = extract_dataset('test', MEL_FILE)\n",
    "\n",
    "df_tp = pd.read_csv(f'train_tp.csv')\n",
    "df_test = pd.read_csv(f'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UC4ELqTT53T"
   },
   "outputs": [],
   "source": [
    "ONE_HOT = np.eye(NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6uPSYkyTj8G2"
   },
   "outputs": [],
   "source": [
    "def create_test_df(dfx):\n",
    "    \"\"\"\n",
    "    Takes the test dataframe and creates a new dataframe with multiple time ranges for each recording id.\n",
    "    This is in order for the test dataframe to mimic the train dataframe.\n",
    "    Arguments:\n",
    "        dfx {DataFrame} - Submission file with each row being a unqiue recording_id\n",
    "    Returns\n",
    "        DataFrame - Submission file with multiple rows and timestamps for each recording_id\n",
    "    \"\"\"\n",
    "\n",
    "    def summary_row(row):\n",
    "        stride = 1\n",
    "        cuts = np.vstack([[i,i+SAMPLE_TIME] for i in range(0, AUDIO_LENGTH-stride, stride)])\n",
    "        row_new = pd.DataFrame(data={'recording_id': row.iloc[0, 0],\n",
    "                        't_min': cuts[:, 0],\n",
    "                        't_max': cuts[:, 1]\n",
    "                        })\n",
    "        return row_new\n",
    "\n",
    "    df_new = dfx.groupby(['recording_id'], as_index=False).apply(summary_row).reset_index(drop=True)\n",
    "    return df_new\n",
    "\n",
    "\n",
    "def smooth_projections(dfx):\n",
    "    \"\"\"\n",
    "    Takes the dataframe and creates a running average of each score through time and then\n",
    "    takes the max value at every point. The dataframe is then pivoted to created the submission\n",
    "    file where every row is a single recording and the columns are all the class scores.\n",
    "    Arguments:\n",
    "        dfx {DataFrame} - Input dataframe where each row is a single strong label projection\n",
    "    Returns\n",
    "        DataFrame - Submission formatted dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_average(row):\n",
    "        # Smooth out with a running average of 3 seconds and then take the max value accross entire 60 second sample\n",
    "        row.drop(['t_min', 't_max', 'fold'], axis=1, inplace=True)\n",
    "        row = row.rolling(3).mean()\n",
    "        row = row.max().T\n",
    "        return row\n",
    "    \n",
    "    dfx.sort_values(['t_min'], inplace=True)\n",
    "    dfx = dfx.groupby(['recording_id', 'fold']).apply(get_average).reset_index()\n",
    "    dfx.columns = ['recording_id', 'fold', 'column', 'score']\n",
    "\n",
    "    dfx = pd.pivot_table(dfx, index=['recording_id', 'fold'], columns=['column'], values=['score']).reset_index()\n",
    "    dfx.drop([('score', 'recording_id')], axis=1, inplace=True)\n",
    "    dfx.columns = [i if i != 'score' else j for i, j in dfx.columns]\n",
    "    dfx = dfx[['fold', 'recording_id'] + [f's{i}' for i in range(len(dfx.columns) - 2)]]\n",
    "    return dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gXcv3h1jvPH-"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model, all=False):\n",
    "    \"\"\"\n",
    "    Count the parameters of a model\n",
    "    Arguments:\n",
    "        model {torch module} - Model to count the parameters of\n",
    "        all {bool} - Whether to include not trainable parameters in the sum (default: {False})\n",
    "    Returns:\n",
    "        int - Number of parameters\n",
    "    \"\"\"\n",
    "    if all:\n",
    "        return sum(p.numel() for p in model.parameters())\n",
    "    else:\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0wtKNtCZ7hA"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Image augmentation classes, that are not used in the final models\n",
    "\"\"\"\n",
    "class SpecAugment(object):\n",
    "    def __init__(self, prob=0.5, num_mask=2, freq_masking_max_percentage=0.05, time_masking_max_percentage=0.15):\n",
    "        self.num_mask = num_mask\n",
    "        self.freq_masking_max_percentage = freq_masking_max_percentage\n",
    "        self.time_masking_max_percentage = time_masking_max_percentage\n",
    "        self.prob = prob\n",
    "        \n",
    "    def __call__(self, spec):\n",
    "        if torch.rand(1) < self.prob:\n",
    "            for i in range(self.num_mask):\n",
    "                _, all_freqs_num, all_frames_num = spec.shape\n",
    "                freq_percentage = random.uniform(0.0, self.freq_masking_max_percentage)\n",
    "                \n",
    "                num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "                f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "                f0 = int(f0)\n",
    "                spec[:, f0:f0 + num_freqs_to_mask, :] = 0\n",
    "\n",
    "                time_percentage = random.uniform(0.0, self.time_masking_max_percentage)\n",
    "                \n",
    "                num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "                t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "                t0 = int(t0)\n",
    "                spec[:, :, t0:t0 + num_frames_to_mask] = 0\n",
    "    \n",
    "        return spec\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__\n",
    "\n",
    "\n",
    "class MonoToColor(object):\n",
    "    def __init__(self, eps=1e-6, mean=None, std=None):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.eps = eps\n",
    "\n",
    "    def __call__(self, X):\n",
    "        # Standardize\n",
    "        mean = self.mean or X.mean()\n",
    "        std = self.std or X.std()\n",
    "        X = (X - mean) / (std + self.eps)\n",
    "\n",
    "        # Normalize to [0, 255]\n",
    "        _min, _max = X.min(), X.max()\n",
    "\n",
    "        if (_max - _min) > self.eps:\n",
    "            V = np.clip(X, _min, _max)\n",
    "            V = 255 * (V - _min) / (_max - _min)\n",
    "            V = V.astype(np.uint8)\n",
    "        else:\n",
    "            V = np.zeros_like(X, dtype=np.uint8)\n",
    "\n",
    "        V = np.stack([V, V, V], axis=-1)\n",
    "        V = V.astype(np.uint8)\n",
    "        return V\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__\n",
    "\n",
    "\n",
    "class GaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=0.5, sigma=0.3, prob=0.5):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        self.sigma = sigma\n",
    "        self.prob = prob\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        if torch.rand(1) < self.prob:\n",
    "            sample_noise = torch.randn(tensor.size()) * self.std + self.mean\n",
    "            sample_noise *= self.sigma\n",
    "            tensor += sample_noise\n",
    "        return tensor\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L7wgLTj8UfrS"
   },
   "outputs": [],
   "source": [
    "def get_model(name, num_classes=1):\n",
    "    \"\"\"\n",
    "    Loads a pretrained model. \n",
    "    Supports ResNest, ResNext-wsl, EfficientNet, ResNext and ResNet.\n",
    "    Arguments:\n",
    "        name {str} - Name of the model to load\n",
    "        num_classes {int} - Number of classes to use (default: {1})\n",
    "    Returns:\n",
    "        torch model - Pretrained model\n",
    "    \"\"\"\n",
    "\n",
    "    if \"resnest\" in name:\n",
    "        model = getattr(resnest_torch, name)(pretrained=True)\n",
    "    elif \"wsl\" in name:\n",
    "        model = torch.hub.load(\"facebookresearch/WSL-Images\", name)\n",
    "    elif \"resnext\" in name or \"resnet\" in name or 'densenet' in name:\n",
    "        model = torch.hub.load(\"pytorch/vision:v0.6.0\", name, pretrained=True)\n",
    "    elif \"efficientnet\" in name:\n",
    "        model = EfficientNet.from_pretrained(name)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    if \"efficientnet\" not in name and \"se\" not in name:\n",
    "        nb_ft = model.fc.in_features\n",
    "        del model.fc\n",
    "        model.fc = nn.BatchNorm1d(nb_ft)\n",
    "    elif 'densenet' in name:\n",
    "        nb_ft = model.classifier.in_features\n",
    "        del model.classifier\n",
    "        model.classifier = nn.BatchNorm1d(nb_ft)\n",
    "    else:\n",
    "        nb_ft = model._fc.in_features\n",
    "        del model._fc\n",
    "        model._fc = nn.BatchNorm1d(nb_ft)\n",
    "\n",
    "    layers = 64\n",
    "    dropout = 0.3\n",
    "\n",
    "    modules = [\n",
    "                model,\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(nb_ft, layers),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(layers),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(layers, num_classes)\n",
    "               ]\n",
    "\n",
    "    return nn.Sequential(*modules) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k7ryfVoKFwEE"
   },
   "outputs": [],
   "source": [
    "def cut_train(x):\n",
    "    \"\"\"\n",
    "    Cuts the full 60 second sample to only include the window which includes the labelled audio.\n",
    "    Then takes a random sub-crop around that sample so that the sample only includes part of the audio.\n",
    "    \"\"\"\n",
    "    full = x['audio_spec'].shape[1] \n",
    "    adj = full / AUDIO_LENGTH\n",
    "\n",
    "    center = (x['t_max'] + x['t_min']) / 2\n",
    "\n",
    "    tmax = center + CUT / 2\n",
    "    tmin = center - CUT / 2\n",
    "\n",
    "    # If the box would stretch beyond limits of the audio sample (0-60 seconds) then shift the box back within the limits\n",
    "    extra_min = max(0, tmax - AUDIO_LENGTH)\n",
    "    extra_max = -min(0, tmin)\n",
    "    start_cut = max(0, tmin) - extra_min\n",
    "    end_cut = min(AUDIO_LENGTH, tmax) + extra_max\n",
    "\n",
    "    # Trim both the start and stop locations    \n",
    "    half_time = (CUT - SAMPLE_TIME) / 2\n",
    "    # Random selection from the window\n",
    "    extra = np.random.uniform(-half_time, half_time)\n",
    "\n",
    "    start_cut += extra + half_time\n",
    "    end_cut += extra - half_time\n",
    "\n",
    "    start_cut = int(start_cut * adj)\n",
    "    end_cut = int(end_cut * adj)\n",
    "\n",
    "    x['audio_spec'] = x['audio_spec'][:, start_cut: end_cut]\n",
    "    return x\n",
    "\n",
    "\n",
    "def cut_test(x):\n",
    "    \"\"\"\n",
    "    Crops the 60 second audio to a window with the sample centered around the t_min and t_max values.\n",
    "    Although the test set doesn't include a t_min and t_max, I artificially create a range for this\n",
    "    with the create_test_df function.\n",
    "    \"\"\"\n",
    "    full = x['audio_spec'].shape[1]\n",
    "    adj = full / AUDIO_LENGTH\n",
    "\n",
    "    tmax = x['t_max']\n",
    "    tmin = x['t_min']\n",
    "\n",
    "    half_length = SAMPLE_TIME / 2\n",
    "    center = (tmax + tmin) / 2\n",
    "    \n",
    "    # If the box would stretch beyond limits then shift the box back\n",
    "    extra_min = max(0, center + half_length - AUDIO_LENGTH)\n",
    "    extra_max = -min(0, center - half_length)\n",
    "    \n",
    "    start_cut = max(0, center - half_length) - extra_min\n",
    "    end_cut = min(AUDIO_LENGTH, center + half_length) + extra_max\n",
    "\n",
    "    start_cut = int(start_cut * adj)\n",
    "    end_cut = int(end_cut * adj)\n",
    "\n",
    "    x['audio_spec'] = x['audio_spec'][:, start_cut:end_cut]\n",
    "    return x\n",
    "\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, data=train_data, train=True):\n",
    "        self.train = train\n",
    "        self.data = data\n",
    "        self.files = df['recording_id'].values\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.y = [ONE_HOT[int(i)] for i in df['species_id'].values]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files) \n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        recording_id = self.files[idx]\n",
    "        data = self.df.iloc[idx, :]\n",
    "        X = self.data[recording_id]\n",
    "        species_id = data['species_id']\n",
    "\n",
    "        output = {\n",
    "            'audio_spec': X,\n",
    "            'recording_id': recording_id,\n",
    "            'species_id': species_id,\n",
    "            't_min': data['t_min'],\n",
    "            't_max': data['t_max'],\n",
    "            'target': self.y[idx],\n",
    "        }\n",
    "\n",
    "        if self.train:\n",
    "            output = cut_train(output)\n",
    "        else:\n",
    "            output = cut_test(output)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(output['audio_spec'])\n",
    "            image = image.numpy()\n",
    "            output['audio_spec'] = image\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, data=test_data):\n",
    "        self.data = data\n",
    "        self.files = df['recording_id'].values\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files) \n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        recording_id = self.files[idx]\n",
    "        X = self.data[recording_id]\n",
    "        data = self.df.iloc[idx, :]\n",
    "\n",
    "        output = {\n",
    "            'audio_spec': X,\n",
    "            't_min': data['t_min'],\n",
    "            't_max': data['t_max']\n",
    "        }\n",
    "\n",
    "        output = cut_test(output)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(output['audio_spec'])\n",
    "            image = image.numpy()\n",
    "\n",
    "        return {\n",
    "            'audio_spec': image,\n",
    "            'recording_id': recording_id\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SMi2bLSCSL2x"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Competition metric functions from https://www.kaggle.com/c/rfcx-species-audio-detection/discussion/198418\n",
    "\"\"\"\n",
    "def _one_sample_positive_class_precisions(scores, truth):\n",
    "    num_classes = scores.shape[0]\n",
    "    pos_class_indices = np.flatnonzero(truth > 0)\n",
    "\n",
    "    if not len(pos_class_indices):\n",
    "        return pos_class_indices, np.zeros(0)\n",
    "\n",
    "    retrieved_classes = np.argsort(scores)[::-1]\n",
    "\n",
    "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
    "    class_rankings[retrieved_classes] = range(num_classes)\n",
    "\n",
    "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
    "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
    "\n",
    "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
    "\n",
    "    precision_at_hits = (\n",
    "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
    "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
    "    return pos_class_indices, precision_at_hits\n",
    "\n",
    "\n",
    "def lwlrap(truth, scores):\n",
    "    assert truth.shape == scores.shape\n",
    "    num_samples, num_classes = scores.shape\n",
    "    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
    "    for sample_num in range(num_samples):\n",
    "        pos_class_indices, precision_at_hits = _one_sample_positive_class_precisions(scores[sample_num, :], truth[sample_num, :])\n",
    "        precisions_for_samples_by_classes[sample_num, pos_class_indices] = precision_at_hits\n",
    "\n",
    "    labels_per_class = np.sum(truth > 0, axis=0)\n",
    "    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
    "\n",
    "    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
    "                        np.maximum(1, labels_per_class))\n",
    "    return per_class_lwlrap, weight_per_class\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "AverageMeter and MetricMeter objects from https://www.kaggle.com/gopidurgaprasad/rfcs-audio-detection-pytorch-stater\n",
    "\"\"\"\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class MetricMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.y_true = []\n",
    "        self.y_pred = []\n",
    "    \n",
    "    def update(self, y_true, y_pred):\n",
    "        self.y_true.extend(y_true.cpu().detach().numpy().tolist())\n",
    "        self.y_pred.extend(torch.sigmoid(y_pred).cpu().detach().numpy().tolist())\n",
    "\n",
    "    @property\n",
    "    def avg(self):\n",
    "        score_class, weight = lwlrap(np.array(self.y_true), np.array(self.y_pred))\n",
    "        self.score = (score_class * weight).sum()\n",
    "\n",
    "        return {\"lwlrap\" : self.score}\n",
    "\n",
    "\"\"\"\n",
    "The below score and loss objects are used to created a History object (similar to that in tensorflow),\n",
    "which stores the full results from each run for easy visualization and logging.\n",
    "\"\"\"\n",
    "class Score(object):\n",
    "    def __init__(self, target='max'):\n",
    "        self.target = target\n",
    "        self.target_func = max if target == 'max' else min\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.values = []\n",
    "        self.best_index = None\n",
    "        self.best = float('inf') if self.target == 'min' else -float('inf')\n",
    "\n",
    "    def update(self, value):\n",
    "        self.values.append(value)\n",
    "        self.best = self.target_func(self.best, value)\n",
    "        if self.best == value:\n",
    "            self.best_index = len(self.values) - 1\n",
    "    \n",
    "    @property\n",
    "    def improved(self):\n",
    "        return self.best_index == len(self.values) - 1\n",
    "\n",
    "    \n",
    "class ScoreLoss(object):\n",
    "    def __init__(self, score_target='max', loss_target='min'):\n",
    "        self.score_target = 'max'\n",
    "        self.loss_target = 'min'\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.score = Score(target=self.score_target)\n",
    "        self.loss = Score(target=self.loss_target)\n",
    "    \n",
    "    def update(self, loss, score):\n",
    "        self.score.update(score)\n",
    "        self.loss.update(loss)\n",
    "    \n",
    "    @property\n",
    "    def score_improved(self):\n",
    "        return self.score.improved\n",
    "\n",
    "    @property\n",
    "    def loss_improved(self):\n",
    "        return self.loss.improved\n",
    "\n",
    "\n",
    "class History(object):\n",
    "    def __init__(self, score_target='max', loss_target='min'):\n",
    "        self.score_target = 'max'\n",
    "        self.loss_target = 'min'\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.val = ScoreLoss(score_target=self.score_target, loss_target=self.loss_target)\n",
    "        self.train = ScoreLoss(score_target=self.score_target, loss_target=self.loss_target)\n",
    "        self.pred = None\n",
    "        self.model_weights = None\n",
    "    \n",
    "    def update(self, loss, score, val_loss, val_score):\n",
    "        self.val.update(val_loss, val_score)\n",
    "        self.train.update(loss, score)\n",
    "\n",
    "    def update_pred(self, pred, model):\n",
    "        if self.score_improved:\n",
    "            self.pred = pred\n",
    "            self.model_weights = model.state_dict()\n",
    "    \n",
    "    @property\n",
    "    def history(self):\n",
    "        return {\n",
    "            'loss': self.train.loss.values,\n",
    "            'score': self.train.score.values,\n",
    "            'val_loss': self.val.loss.values,\n",
    "            'val_score': self.val.score.values\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def best_result(self):\n",
    "        return {\n",
    "            'score': self.val.score.best,\n",
    "            'loss': self.val.loss.values[self.val.score.best_index]\n",
    "        }\n",
    "    \n",
    "    @property\n",
    "    def score_improved(self):\n",
    "        return self.val.score_improved\n",
    "\n",
    "    @property\n",
    "    def loss_improved(self):\n",
    "        return self.val.loss_improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SN2lCEa7zKlo"
   },
   "outputs": [],
   "source": [
    "def plot_history(history, filename):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        history {History class} - history object either from tensorflow or from the object outlined above\n",
    "        filename {String} - directory to save a png copy of the graph\\\n",
    "    \"\"\"\n",
    "    validation = history.history[\"val_loss\"]\n",
    "    score = history.history[\"val_score\"]\n",
    "    best_score = max(score)\n",
    "    index_score = score.index(best_score)\n",
    "    print(f'epoch: {index_score + 1}, loss: {validation[index_score]:.4f}, score: {best_score:.4}')\n",
    "\n",
    "    plt.style.use('dark_background')\n",
    "    plt.rcParams.update({'font.size': 15, 'axes.xmargin': 0})\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(20,8))\n",
    "    ax1.plot(history.history['score'])\n",
    "    ax1.plot(history.history['val_score'])\n",
    "    ax1.set_title('score')\n",
    "    ax1.set_ylabel('score')\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax1.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "    ax2.plot(history.history['loss'])\n",
    "    ax2.plot(history.history['val_loss'])\n",
    "    ax2.set_title('loss')\n",
    "    ax2.set_ylabel('loss')\n",
    "    ax2.set_xlabel('epoch')\n",
    "    ax2.legend(['train', 'val'], loc='upper right')\n",
    "    plt.show()\n",
    "    try:\n",
    "        plt.savefig(filename)\n",
    "    except:\n",
    "        print('Failed image save')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDg_rFcUcEFh"
   },
   "outputs": [],
   "source": [
    "def load_model_weights(model, filename, verbose=1, cp_folder=\"\"):\n",
    "    \"\"\"\n",
    "    Loads the weights of a PyTorch model. The exception handles cpu/gpu incompatibilities\n",
    "    Arguments:\n",
    "        model {torch module} - Model to load the weights to\n",
    "        filename {str} - Name of the checkpoint\n",
    "        verbose {int} - Whether to display infos (default: {1})\n",
    "        cp_folder {str} - Folder to load from (default: {''})\n",
    "    Returns:\n",
    "        torch module - Model with loaded weights\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"\\n -> Loading weights from {os.path.join(cp_folder,filename)}\\n\")\n",
    "    try:\n",
    "        model.load_state_dict(os.path.join(cp_folder, filename), strict=strict)\n",
    "    except BaseException:\n",
    "        model.load_state_dict(\n",
    "            torch.load(os.path.join(cp_folder, filename), map_location=\"cpu\"),\n",
    "            strict=True,\n",
    "        )\n",
    "    return model\n",
    "\n",
    "\n",
    "def save_model_weights(model, filename, verbose=1, cp_folder=\"\"):\n",
    "    \"\"\"\n",
    "    Saves the weights of a PyTorch model\n",
    "    Arguments:\n",
    "        model {torch module} - Model to save the weights of\n",
    "        filename {str} - Name of the checkpoint\n",
    "        verbose {int} - Whether to display infos (default: {1})\n",
    "        cp_folder {str} - Folder to save to (default: {''})\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"\\n -> Saving weights to {os.path.join(cp_folder, filename)}\\n\")\n",
    "    torch.save(model.state_dict(), os.path.join(cp_folder, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfhAOJ8w2OFM"
   },
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=0.4):\n",
    "    \"\"\"\n",
    "    Applies mixup to a sample\n",
    "    Arguments:\n",
    "        x {torch tensor} - Input batch\n",
    "        y {torch tensor} - Labels\n",
    "        alpha {float} - Parameter of the beta distribution (default: {0.4})\n",
    "    Returns:\n",
    "        torch tensor - Mixed input\n",
    "        torch tensor - Labels of the original batch\n",
    "        torch tensor - Labels of the shuffle batch\n",
    "        float - Probability samples by the beta distribution\n",
    "    \"\"\"\n",
    "    lam = np.random.beta(alpha, alpha) if alpha > 0 else 1\n",
    "\n",
    "    index = torch.randperm(x.size()[0]).cuda()\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def fit(\n",
    "    model,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    val_bs=32,\n",
    "    warmup_prop=0.1,\n",
    "    lr=1e-3,\n",
    "    alpha=0.4,\n",
    "    mixup_proba=0.0,\n",
    "    accum_gradient=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Usual torch fit function\n",
    "    Arguments:\n",
    "        model {torch model} - Model to train\n",
    "        train_dataset {torch dataset} - Dataset to train with\n",
    "        val_dataset {torch dataset} - Dataset to validate with\n",
    "        epochs {int} - Number of epochs (default: {50})\n",
    "        batch_size {int} - Training batch size (default: {32})\n",
    "        val_bs {int} - Validation batch size (default: {32})\n",
    "        warmup_prop {float} - Warmup proportion (default: {0.1})\n",
    "        lr {float} - Start (or maximum) learning rate (default: {1e-3})\n",
    "        alpha {float} - alpha value for mixup (default: {0.4})\n",
    "        mixup_proba {float} - Probability to apply mixup (default: {0.})\n",
    "        accum_gradient {int} - After how many samples should you back-prop\n",
    "    Returns:\n",
    "        history {History} - Full history of every epoch (score, loss and dict of best model weights)\n",
    "    \"\"\"\n",
    "    losses = AverageMeter()\n",
    "    scores = MetricMeter()\n",
    "    history = History()\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    loss_fct = nn.BCEWithLogitsLoss(reduction=\"mean\").cuda()\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        pin_memory=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=val_bs,\n",
    "        shuffle=False,\n",
    "        pin_memory=True, \n",
    "        num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    num_warmup_steps = int(warmup_prop * epochs * len(train_loader))\n",
    "    num_training_steps = int(epochs * len(train_loader))\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps, num_training_steps\n",
    "    )\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        avg_loss = 0\n",
    "        scores.reset()\n",
    "        losses.reset()\n",
    "\n",
    "        for step, sample in enumerate(train_loader):\n",
    "            X, y = sample['audio_spec'], sample['target']\n",
    "\n",
    "\n",
    "            if np.random.rand() < mixup_proba:\n",
    "                X, y_a, y_b, _ = mixup_data(X.cuda(), y.cuda(), alpha=alpha)\n",
    "                y = torch.clamp(y_a + y_b, 0, 1)\n",
    "\n",
    "            y_pred = model(X.cuda())\n",
    "            loss = loss_fct(y_pred, y.cuda().float())\n",
    "\n",
    "            scores.update(y, y_pred)\n",
    "            losses.update(loss.item(), len(X))\n",
    "            \n",
    "            \"\"\"\n",
    "            For large models gpu restrictions require very small batch sizes, but we still want to back-prop the gradient at\n",
    "            larger batch sizes. accum_gradient if an interger will only step the gradient after every multiple of the\n",
    "            accum_gradient size (e.g accum_gradient=32 and batch_size=8 will back-prop the gradients after every 4th batch)\n",
    "            \"\"\"\n",
    "            if accum_gradient is None:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                scheduler.step()\n",
    "            else:\n",
    "                x_steps = accum_gradient // batch_size\n",
    "                if step % x_steps == 0 or (step+2)*batch_size >= len(train_dataset):\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    scheduler.step()\n",
    "\n",
    "        losses_val = AverageMeter()\n",
    "        scores_val = MetricMeter()\n",
    "\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = np.empty((0, NUM_CLASSES))\n",
    "\n",
    "            for step, sample in enumerate(val_loader):\n",
    "                X, y = sample['audio_spec'], sample['target']\n",
    "\n",
    "                y_pred = model(X.cuda()).detach()\n",
    "                loss = loss_fct(y_pred, y.cuda().float())\n",
    "\n",
    "                total_loss += loss.item() * len(y_pred)\n",
    "                preds = np.concatenate([preds, torch.sigmoid(y_pred).cpu().numpy()])\n",
    "\n",
    "\n",
    "        y, y_pred = torch.tensor(val_dataset.y), torch.tensor(preds)\n",
    "\n",
    "        total_loss /= len(preds)\n",
    "        scores_val.update(y, y_pred)\n",
    "        losses_val.update(total_loss, 1)\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} \\t lr={lr:.1e} \\t t={elapsed_time:.0f}s \\t loss={losses.avg:.4f} \\t score={scores.avg['lwlrap']:.4f} \\t val_loss={losses_val.avg:.4f} \\t val_score={scores_val.avg['lwlrap']:.4f}\")\n",
    "\n",
    "        history.update(loss=losses.avg, \n",
    "                        score=scores.avg['lwlrap'],\n",
    "                        val_loss=losses_val.avg,\n",
    "                        val_score=scores_val.avg['lwlrap'])\n",
    "        \n",
    "        history.update_pred(pred=preds, model=model)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "def predict(model, dataset, batch_size=64, total=1):\n",
    "    \"\"\"\n",
    "    Usual torch predict function\n",
    "    Arguments:\n",
    "        model {torch model} - Model to predict with\n",
    "        dataset {torch dataset} - Dataset to predict with on\n",
    "        batch_size {int} - Batch size (default: {32})\n",
    "        total {int} - Total length of all samples (default: {1})\n",
    "    Returns:\n",
    "        numpy array - Predictions\n",
    "    \"\"\"\n",
    "    loader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    preds = np.empty((0, NUM_CLASSES))\n",
    "    total = math.ceil(total / batch_size)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, sample in tqdm(enumerate(loader), total=total):\n",
    "            X = sample['audio_spec'].cuda()\n",
    "            y_pred = model(X)\n",
    "            y_pred = torch.sigmoid(y_pred).cpu().detach().numpy()\n",
    "            preds = np.concatenate([preds, y_pred])\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o9xY4f0eXvrp"
   },
   "outputs": [],
   "source": [
    "def train(config, df_train, df_val, fold):\n",
    "    global train_data\n",
    "    global test_data\n",
    "\n",
    "    print(f\"    -> {len(df_train)} training samples\")\n",
    "    print(f\"    -> {len(df_val)} validation samples\")\n",
    "\n",
    "    seed_everything(config.seed)\n",
    "    model = get_model(\n",
    "        config.selected_model, num_classes=NUM_CLASSES\n",
    "    )\n",
    "    \n",
    "    if config.gpu:\n",
    "        model = model.cuda()\n",
    "    \n",
    "    model.zero_grad()\n",
    "\n",
    "    train_dataset = AudioDataset(df_train, transform=config.train_transform, data=train_data)\n",
    "    val_dataset = AudioDataset(df_val, transform=config.test_transform, data=train_data, train=False)\n",
    "\n",
    "    n_parameters = count_parameters(model)\n",
    "    print(f\"    -> {n_parameters} trainable parameters\\n\")\n",
    "\n",
    "    history = fit(\n",
    "        model,\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        epochs=config.epochs,\n",
    "        batch_size=config.batch_size,\n",
    "        val_bs=config.val_bs,\n",
    "        lr=config.lr,\n",
    "        warmup_prop=config.warmup_prop,\n",
    "        alpha=config.alpha,\n",
    "        mixup_proba=config.mixup_proba,\n",
    "        accum_gradient=config.accum_gradient\n",
    "    )\n",
    "\n",
    "    # Load the best model back in\n",
    "    model.load_state_dict(history.model_weights)\n",
    "\n",
    "    model_name = f'{config.selected_model}_{config.name}_{fold}'\n",
    "    plot_history(history, f'models/{model_name}.png')\n",
    "\n",
    "    save_model_weights(\n",
    "        model,\n",
    "        f\"{model_name}.pt\",\n",
    "        cp_folder=f'models',\n",
    "    )\n",
    "\n",
    "    return history\n",
    "\n",
    "def test(config, dfx):\n",
    "    global test_data\n",
    "    dfx = create_test_df(dfx)\n",
    "    test_dataset = TestDataset(dfx, transform=config.test_transform, data=test_data)\n",
    "\n",
    "    s_names = [f's{i}' for i in range(NUM_CLASSES)]\n",
    "    df_results = []\n",
    "\n",
    "    for fold in range(config.k):\n",
    "        model = get_model(\n",
    "            config.selected_model, num_classes=NUM_CLASSES\n",
    "        )\n",
    "\n",
    "        model = load_model_weights(\n",
    "            model,\n",
    "            f\"{config.selected_model}_{config.name}_{fold}.pt\",\n",
    "            cp_folder=f'models',\n",
    "        )\n",
    "\n",
    "        if config.gpu:\n",
    "            model = model.cuda()\n",
    "\n",
    "        pred = predict(model=model, dataset=test_dataset, batch_size=config.batch_size, total=dfx.shape[0])\n",
    "\n",
    "        # Store results into a dataframe and get the max results for each fold\n",
    "        df_result = pd.DataFrame(data=pred, columns=s_names)\n",
    "        df_result['recording_id'] = test_dataset.df['recording_id']\n",
    "        df_result['t_min'] = test_dataset.df['t_min']\n",
    "        df_result['t_max'] = test_dataset.df['t_max']\n",
    "        df_result['fold'] = fold\n",
    "        df_results.append(df_result)\n",
    "\n",
    "    df_results = pd.concat(df_results, axis=0)\n",
    "    df_results.to_csv('submissions/test_oof.csv', index=False)\n",
    "\n",
    "    df_results = smooth_projections(df_results)\n",
    "    df_results.drop(['fold'], axis=1, inplace=True)\n",
    "    \n",
    "    # Average over all the folds\n",
    "    df_results = df_results.groupby(['recording_id'], as_index=False).agg(['sum'])\n",
    "    df_results.columns = [i for i, _ in df_results.columns]\n",
    "\n",
    "    return df_results\n",
    "\n",
    "\n",
    "def k_fold(config, dfx):\n",
    "    \"\"\"\n",
    "    Create cross validated folds without having the same recording_id in different folds (possible leakage) as some samples\n",
    "    come from the same recording just at different time ranges.\n",
    "    \"\"\"\n",
    "    group_kfold = GroupKFold(n_splits=config.k)\n",
    "    splits = list(group_kfold.split(dfx, dfx['species_id'], dfx['recording_id']))\n",
    "\n",
    "    pred_oof = []\n",
    "    histories = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    df_result = []\n",
    "\n",
    "    for i, (train_idx, val_idx) in enumerate(splits):\n",
    "        if i in config.selected_folds:\n",
    "            print(f\"\\n-------------   Fold {i + 1} / {config.k}  -------------\\n\")\n",
    "\n",
    "            df_train = dfx.iloc[train_idx].copy()\n",
    "            df_val = dfx.iloc[val_idx].copy()\n",
    "            df_result.append(df_val)\n",
    "\n",
    "            history = train(config, df_train, df_val, i)\n",
    "            histories.append(history)\n",
    "            pred_oof += history.pred.tolist()\n",
    "\n",
    "    # Print out summary of each fold's time and best scores\n",
    "    minutes, seconds = divmod(time.time() - start_time, 60)\n",
    "    avg_score = sum([i.best_result['score'] for i in histories]) / len(histories)\n",
    "    avg_loss = sum([i.best_result['loss'] for i in histories]) / len(histories)\n",
    "    print(f\"\\n-------------   AVG over folds -------------\\n\")\n",
    "    print(f't={minutes}min val_loss={avg_loss:.4f} val_score={avg_score:.4f}')\n",
    "\n",
    "    # Add the results back together\n",
    "    df_result = pd.concat(df_result, axis=0, ignore_index=True)\n",
    "    for i in range(NUM_CLASSES):\n",
    "        df_result[f's{i}'] = np.array(pred_oof)[:, i]\n",
    "\n",
    "    # Save a copy of every individual folds results\n",
    "    df_result.to_csv(f'submissions/oof.csv', index=False)\n",
    "\n",
    "    return df_result, avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fELKap6NXy7c"
   },
   "outputs": [],
   "source": [
    "# ImageNet normalization\n",
    "norm = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "class Config:\n",
    "    seed = 2020\n",
    "    gpu = True\n",
    "\n",
    "    k = 5\n",
    "    selected_folds = [0,1,2,3,4] \n",
    "\n",
    "    name = \"final\"\n",
    "    selected_model = 'efficientnet-b3'\n",
    "    # selected_model = \"resnest50_fast_1s1x64d\"\n",
    "    \n",
    "    batch_size = 32\n",
    "    val_bs = 32\n",
    "\n",
    "    epochs = 200\n",
    "    lr = 1e-3\n",
    "    warmup_prop = 0.05\n",
    "    accum_gradient = 32\n",
    "\n",
    "    mixup_proba = 0.\n",
    "    alpha = 0.1\n",
    "    train_transform = transforms.Compose([\n",
    "                                MonoToColor(),\n",
    "                                transforms.ToPILImage(),\n",
    "                                transforms.Resize((HEIGHT,WIDTH)),\n",
    "                                transforms.ToTensor(),\n",
    "                                norm,\n",
    "                                ])\n",
    "    test_transform = transforms.Compose([\n",
    "                                MonoToColor(),\n",
    "                                transforms.ToPILImage(),\n",
    "                                transforms.Resize((HEIGHT,WIDTH)),\n",
    "                                transforms.ToTensor(),\n",
    "                                norm\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-lbdPNjAkasJ",
    "outputId": "f9ff7d8d-94c4-4dc3-ebd0-8d56924f2200"
   },
   "outputs": [],
   "source": [
    "val_result, score = k_fold(config=Config, dfx=df_tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xPF7AunpjCZ-",
    "outputId": "09c09296-3823-4441-b345-65153d7e3471"
   },
   "outputs": [],
   "source": [
    "result = test(config=Config, dfx=df_test.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vj_xJsdajB5x"
   },
   "outputs": [],
   "source": [
    "TODAY = str(datetime.date.today())\n",
    "file_name = f\"{TODAY}_{Config.selected_model}_{Config.name}_{score:.4f}\"\n",
    "result.to_csv(f'submissions/{file_name}.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "kaggle_rainforest",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
